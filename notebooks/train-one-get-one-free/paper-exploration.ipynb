{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook exploratório\n",
    "\n",
    "- Artigo: Train one get one free\n",
    "- Link: https://arxiv.org/abs/1903.12431"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Inicializando o GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = tt.vocab.GloVe('6B', dim=50)\n",
    "glove_vocab = set(glove.stoi.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Carregando dados de uma das bases para exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>short_desc</th>\n    </tr>\n    <tr>\n      <th>bug_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Usability issue with external editors (1GE6IRL)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Opening repository resources doesn't honor typ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sync does not indicate deletion (1GIEN83)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>need better error message if catching up over ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ISharingManager sharing API inconsistent (1GAU...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                               short_desc\nbug_id                                                   \n1         Usability issue with external editors (1GE6IRL)\n2       Opening repository resources doesn't honor typ...\n3               Sync does not indicate deletion (1GIEN83)\n4       need better error message if catching up over ...\n5       ISharingManager sharing API inconsistent (1GAU..."
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclipse = pd.read_csv('../../data/processed/eclipse.csv', index_col='bug_id')\n",
    "eclipse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Preprocessamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "bug_id\n1        usability issue with external editors 1ge6irl\n2    opening repository resources doesnt honor type...\n3              sync does not indicate deletion 1gien83\n4    need better error message if catching up over ...\n5     isharingmanager sharing api inconsistent 1gaul8h\nName: short_desc, dtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_nonalpha = lambda word: ''.join([x for x in word if str.isalpha(x) or str.isnumeric(x) or x == ' '])\n",
    "\n",
    "short_desc = eclipse['short_desc']\n",
    "short_desc = short_desc.apply(str.lower)\n",
    "short_desc = short_desc.apply(remove_nonalpha)\n",
    "short_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Explorando vocabulário das descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "111313"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_freq = defaultdict(int)\n",
    "for sentence in short_desc:\n",
    "    for word in sentence.split():\n",
    "        base_freq[word] += 1\n",
    "base_vocab = set(base_freq.keys())\n",
    "len(base_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Explorando diferenças entre vocabulário do GloVe e das descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palavras distintas:  94763\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de palavras distintas: \", len(base_vocab - glove_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Removendo palavras menos frequentes do vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palavras do vocabulário:  17026\n",
      "Número de palavras compartilhadas entre os dois vocabulários:  9193\n",
      "Número de palavras distintas:  7833\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 3\n",
    "\n",
    "base_freq = {key: value for key, value in base_freq.items() if value > MIN_FREQ}\n",
    "base_freq\n",
    "base_vocab = set(base_freq.keys())\n",
    "print(\"Número de palavras do vocabulário: \", len(base_vocab))\n",
    "print(\"Número de palavras compartilhadas entre os dois vocabulários: \", len(base_vocab & glove_vocab))\n",
    "print(\"Número de palavras distintas: \", len(base_vocab - glove_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Obtendo pesos das palavras existentes no vocabulário do GloVe\n",
    "\n",
    "* Obtendo palavras que estão dentro do vocabulário do GloVe\n",
    "* Extraindo o STOI das palavras que estão apenas no vocabulário\n",
    "* Obtendo os vetores correspondentes as palavras pertencentes ao vocabulário\n",
    "* Gerando um novo STOI iniciado de 0 usando apenas as palavras existentes no vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vocab = base_vocab & glove_vocab\n",
    "in_size = len(in_vocab)\n",
    "\n",
    "in_stoi = {x: glove.stoi[x] for x in in_vocab}\n",
    "in_stoi = {k: v for k, v in sorted(in_stoi.items(), key=lambda x:x[1])}\n",
    "in_vectors = glove.vectors[list(in_stoi.values())]\n",
    "in_stoi = {key: value for key, value in zip(in_stoi.keys(), range(in_size))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Gerando pesos para palavras fora do vocabulário do GloVe\n",
    "\n",
    "* Obtem as palavras que não estão no vocabulário\n",
    "* Gera um vetor de zeros com o shape `[n_palavras_fora_vocab, shape_do_glove]`\n",
    "* Utiliza o vetor de zeros pra gerar um tensor que segue distribuição normal\n",
    "* Gera um STOI para continuar o STOI anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_shape = glove.vectors.shape[-1]\n",
    "\n",
    "out_vocab = sorted(list(base_vocab - glove_vocab))\n",
    "out_size = len(out_vocab)\n",
    "\n",
    "zeros = torch.zeros((out_size, glove_shape))\n",
    "out_vectors = torch.normal(mean=zeros, std=1)\n",
    "\n",
    "out_stoi = {key: value for key, value in zip(out_vocab, range(in_size, in_size + out_size))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Gerando pesos para padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_shape = glove.vectors.shape[-1]\n",
    "zero_vectors = torch.zeros((1, glove_shape))\n",
    "zero_stoi = {\"<PAD>\": in_size + out_size}\n",
    "zero_id = zero_stoi['<PAD>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Unindo representações\n",
    "\n",
    "* Primeiros elementos são os caras presentes no GloVe\n",
    "* Próximos elementos são os que não estão presentes no GloVe\n",
    "* Seguido por um elemento que representa padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário final:  17027\n",
      "Shape do vetor final:  torch.Size([17027, 50])\n"
     ]
    }
   ],
   "source": [
    "base_vectors = torch.cat((in_vectors, out_vectors, zero_vectors))\n",
    "base_stoi = {**in_stoi, **out_stoi, **zero_stoi}\n",
    "\n",
    "print(\"Tamanho do vocabulário final: \", len(base_stoi))\n",
    "print(\"Shape do vetor final: \", base_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Implementando tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVeTokenizer(object):\n",
    "    def __init__(self, stoi, max_size):\n",
    "        self.stoi = stoi\n",
    "        self.max_sentence_size = max_size\n",
    "        self.PADDING_CHAR = '<PAD>'\n",
    "    def tokenize(self, sentences):\n",
    "        max_sentence_size = self.max_sentence_size\n",
    "        tokenized_sentences = list()\n",
    "        for sentence in sentences:\n",
    "            tok_index = 0\n",
    "            tokenized_sentence = list()\n",
    "            for word in sentence.split():\n",
    "                if word in self.stoi and tok_index < max_sentence_size:\n",
    "                    tokenized_sentence.append([self.stoi[word]])\n",
    "                    tok_index += 1\n",
    "            for i in range(tok_index, max_sentence_size):\n",
    "                tokenized_sentence.append([self.stoi[self.PADDING_CHAR]])\n",
    "            tokenized_sentences.append(tokenized_sentence)\n",
    "        return torch.LongTensor(tokenized_sentences)\n",
    "    def tokens_to_onehot(self, tokenized_sentences):\n",
    "        # one liner da internet\n",
    "        # https://stackoverflow.com/questions/36960320/convert-a-2d-matrix-to-a-3d-one-hot-matrix-numpy\n",
    "        input_tensors = (torch.arange(tokenized_sentences.max() + 1) == tokenized_sentences[..., None]).int().squeeze()\n",
    "        return input_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_tok = GloVeTokenizer(base_stoi, max_size=300)\n",
    "tokenized_words = glove_tok.tokenize(short_desc[:10])\n",
    "onehot_words = glove_tok.tokens_to_onehot(tokenized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([10, 300, 1]), torch.Size([10, 300, 17027]))"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_words.shape, onehot_words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Implementando rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugSimilarityModel(pl.LightningModule):\n",
    "    def __init__(self, word_embedding, embed_dim):\n",
    "        super().__init__()\n",
    "        self.word_embedding = torch.nn.Linear(in_features=word_embedding.shape[0], out_features=word_embedding.shape[-1], bias=False)\n",
    "        self.word_embedding.weights = word_embedding\n",
    "        self.bi_gru = torch.nn.GRU(input_size=word_embedding.shape[-1], hidden_size=embed_dim, batch_first=True, bidirectional=True)\n",
    "        self.self_attention = torch.nn.MultiheadAttention(2*embed_dim, num_heads=1)\n",
    "        self.conditional_attention = torch.nn.MultiheadAttention(embed_dim, num_heads=1)\n",
    "        self.mlp = torch.nn.Linear(embed_dim, 100)\n",
    "    def forward(self, P, Q):\n",
    "        # Report P\n",
    "        p = self.word_embedding(P)\n",
    "        p_output, p_h_n = self.bi_gru(p)\n",
    "        p_output = p_output.permute(1, 0, 2)\n",
    "        print(p_output.shape)\n",
    "        theta_p = self.self_attention(p_output, p_output, p_output)\n",
    "\n",
    "        # Report Q\n",
    "        #q = self.word_embedding(Q)\n",
    "        #q_output, q_h_n = self.bi_gru(q)\n",
    "        #q_output = q_output.permute(1, 0, 2)\n",
    "        #theta_q = self.self_attention(q_output, q_output, q_output)\n",
    "\n",
    "        return theta_p#, #theta_q\n",
    "\n",
    "        return gru_output_forward, gru_output_backward,h_forward, h_backward\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pass\n",
    "    def configure_optimizers(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BugSimilarityModel(base_vectors, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 10, 200])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[[ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          ...,\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028]],\n \n         [[ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          ...,\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028]],\n \n         [[ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          ...,\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028]],\n \n         ...,\n \n         [[ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          ...,\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028]],\n \n         [[ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          ...,\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028]],\n \n         [[ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          ...,\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0134, -0.0420,  ...,  0.0397, -0.0244,  0.0028],\n          [ 0.0204,  0.0133, -0.0420,  ...,  0.0397, -0.0244,  0.0028]]],\n        grad_fn=<AddBackward0>),\n tensor([[[0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          ...,\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033]],\n \n         [[0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          ...,\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033]],\n \n         [[0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          ...,\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033]],\n \n         ...,\n \n         [[0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          ...,\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033]],\n \n         [[0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          ...,\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033]],\n \n         [[0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          ...,\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033],\n          [0.0033, 0.0033, 0.0033,  ..., 0.0033, 0.0033, 0.0033]]],\n        grad_fn=<DivBackward0>))"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(onehot_words.float(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}